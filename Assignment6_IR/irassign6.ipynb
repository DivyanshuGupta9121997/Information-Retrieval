{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sklearn_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_tab=dict((ord(char), ' ') for char in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(doc):\n",
    "    doc=re.sub(r\"\\d+\",\" \",doc)\n",
    "    doc=doc.translate(tran_tab)\n",
    "    file1=open('english','r')\n",
    "    l_stopwords = file1.read().split()\n",
    "\n",
    "    content=[]\n",
    "    doclist=nltk.word_tokenize(doc)\n",
    "    for w in doclist:\n",
    "        if w.lower() not in l_stopwords:\n",
    "            content.append(w)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    " \n",
    "def remove_stop(example_sent):\n",
    " \n",
    "    stemmer = PorterStemmer()\n",
    "    word_tokens = remove_stopwords(example_sent)\n",
    "    singles = [stemmer.stem(plural) for plural in word_tokens]\n",
    "    return singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "all_docs = []\n",
    "doc_ids = []\n",
    "for root, dirs, files in os.walk(\"20_newsgroups/comp.graphics\"):\n",
    "    for name in files:\n",
    "        try:\n",
    "            all_docs.append(' '.join(remove_stop(codecs.open(os.path.join(root, name), 'r', encoding='utf-8').read())))\n",
    "            doc_ids.append(name)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_representation = sklearn_tfidf.fit_transform(all_docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newsgroup comp graphic path cantaloup srv cs cmu edu rochest udel darwin sura net opusc usceast raynor raynor cs scarolina edu harold brian raynor subject help need hidden line remov messag ID raynor beech cs scarolina edu summari need help robert algorithm hidden line remov keyword hidden line graphic sender usenet usceast cs scarolina edu usenet new system organ usc depart comput scienc distribut comp date apr gmt line look inform hidden line remov use robert algorithm someth code pseudo code would especi help requir class due monday littl time implement chang fast pace class note given class leav lot desir would vastli appreci help actual algorithm would nice robert main problem two object intersect x dimens need know line clip one object appear front anoth give ftp address filenam even name good book realli appreci thank brian raynor'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(list_sen):\n",
    "    return sklearn_tfidf.fit_transform(list_sen).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_for(doc_id, dataset):\n",
    "    return dataset[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_ind(point, kmeans):\n",
    "    min_ind = 0\n",
    "    min_dist = np.linalg.norm(point - kmeans[0])\n",
    "    for i in range(1, len(kmeans)):\n",
    "        dist = np.linalg.norm(point - kmeans[i])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_ind = i\n",
    "#         print(dist, \"TRIVEDI\")\n",
    "    return min_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(vector):\n",
    "    sum = 0\n",
    "    sum += np.sum(vector, axis = 0)\n",
    "    sum /= len(vector)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_loop(dataset, kmeans):\n",
    "    bin = [[] for i in range(len(kmeans))]\n",
    "    for j,point in enumerate(dataset):\n",
    "        min_ind = find_min_ind(point, kmeans)\n",
    "        bin[min_ind].append(j)\n",
    "#         print(min_ind, \" RAg\")\n",
    "    kmeans_new = []\n",
    "    for i in bin:\n",
    "        new_vector = []\n",
    "        for j in i:\n",
    "            new_vector.append(get_vector_for(j, dataset))\n",
    "        kmeans_new.append(find_centroid(new_vector))\n",
    "#         print(find_centroid(new_vector))\n",
    "    print(np.sum(np.sum(np.array(kmeans_new) - np.array(kmeans), axis = 1)))\n",
    "#     kmeans_new = [[find_centroid(get_vector_for(i, dataset))] for i in bin]\n",
    "    return kmeans_new, bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asli_kmeans(k, dataset):\n",
    "    kmeans = dataset[:k]\n",
    "#     kmeans = random.sample(list(dataset), k)\n",
    "    print(kmeans)\n",
    "    for i in range(100):\n",
    "        kmeans, bin = single_loop(dataset, kmeans)\n",
    "    print(kmeans)\n",
    "    return kmeans, bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_vectors([\"cricket bat\", \"cricket ram\",\"football\",  \"ronaldo football\"])\n",
    "kmeans = dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951 TRIVEDI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_min_ind(dataset[2], kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52352552, -0.41275353,  0.5397101 ,  0.        ,  0.26176276])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_centroid([dataset[0], dataset[2], dataset[3]]) - dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "22.009051525364555\n",
      "1.316537452426547\n",
      "-0.11705502926828479\n",
      "1.1885216037968607\n",
      "0.10799703722801224\n",
      "0.670391732339719\n",
      "0.027534085629867415\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-f5f140c36d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masli_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-330-cf9a5d6e742e>\u001b[0m in \u001b[0;36masli_kmeans\u001b[0;34m(k, dataset)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-328-5e07c8f28312>\u001b[0m in \u001b[0;36msingle_loop\u001b[0;34m(dataset, kmeans)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmin_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_min_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mbin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         print(min_ind, \" RAg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-318-c3c3d8e563d4>\u001b[0m in \u001b[0;36mfind_min_ind\u001b[0;34m(point, kmeans)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = int(input())\n",
    "kmeans, bin = asli_kmeans(k, sklearn_representation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
